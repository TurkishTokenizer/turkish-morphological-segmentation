{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6txQNlZvQ8P",
        "outputId": "47c03294-ca84-4c6e-9fb5-7bb3750b883c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynini\n",
            "  Downloading pynini-2.1.7-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Downloading pynini-2.1.7-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (165.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.5/165.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynini\n",
            "Successfully installed pynini-2.1.7\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.12/dist-packages (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "!pip install --only-binary :all: pynini\n",
        "!pip install wurlitzer\n",
        "import pynini\n",
        "%load_ext wurlitzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j_HcAl-2_lcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01a22c9-9114-45c3-ae4f-e5769d693e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LEXICON LOADED\n",
            "============================================================\n",
            "Nouns: 56691 words\n",
            "Verbs: 3455 words (infinitives → roots extracted)\n",
            "Adjectives: 5504 words\n",
            "Pronouns: 50 words\n",
            "Adverbs: 1300 words\n",
            "Conjunctions: 53 words\n",
            "Postpositions: 0 words\n",
            "Proper Nouns: 0 words\n",
            "\n",
            "Verb root examples:\n",
            "  polenlemek → polenle\n",
            "  kubaşmak → kubaş\n",
            "  sayıklamak → sayıkla\n",
            "  ölçeklemek → ölçekle\n",
            "  atkılamak → atkıla\n",
            "\n",
            "============================================================\n",
            "DEBUG: Testing verb compositions\n",
            "============================================================\n",
            "\n",
            "'gel' + verb_imperative:\n",
            "  ✓ gel+VERB+IMP+2SG\n",
            "\n",
            "'gelsin' + verb_imperative:\n",
            "  ✓ gel+VERB+IMP+3SG\n",
            "\n",
            "============================================================\n",
            "SINGLE WORD ANALYSIS\n",
            "============================================================\n",
            "\n",
            "gel:\n",
            "  gel+VERB+IMP+2SG\n",
            "\n",
            "gelin:\n",
            "  gel+VERB+IMP+2PL\n",
            "  gel+VERB+REFL+IMP+2SG\n",
            "  gelin+NOUN\n",
            "\n",
            "gelsin:\n",
            "  gel+VERB+IMP+3SG\n",
            "\n",
            "gelsem:\n",
            "  gel+VERB+COND+1SG\n",
            "\n",
            "geleyim:\n",
            "  gel+VERB+OPT+1SG\n",
            "\n",
            "gelmeli:\n",
            "  gel+VERB+NEC+3SG\n",
            "\n",
            "yazmalıyım:\n",
            "  yaz+VERB+NEC+1SG\n",
            "\n",
            "okusana:\n",
            "  oku+VERB+OPT+2SG+EMPH\n",
            "\n",
            "görseler:\n",
            "  gör+VERB+COND+3PL\n",
            "\n",
            "okudum:\n",
            "  oku+VERB+PAST+1SG\n",
            "\n",
            "gelebilecek:\n",
            "  gel+VERB+ABIL+FUT+3SG\n",
            "\n",
            "geliyorum:\n",
            "  gel+VERB+PRES.CONT+1SG\n",
            "\n",
            "kitaplardan:\n",
            "  kitap+NOUN+PL+ABL\n",
            "\n",
            "kalemlik:\n",
            "  kalem+NOUN+DER.lik\n",
            "\n",
            "evdekiler:\n",
            "  ev+NOUN+LOC+KI+PL\n",
            "\n",
            "============================================================\n",
            "MULTI-WORD ANALYSIS\n",
            "============================================================\n",
            "\n",
            "'evde misin?':\n",
            "  evde:\n",
            "    ev+NOUN+LOC\n",
            "  misin?:\n",
            "    mi+QUES+2SG+PUNCT.question\n",
            "\n",
            "'kitap da güzel':\n",
            "  kitap:\n",
            "    kitap+NOUN\n",
            "  da:\n",
            "    +LOC\n",
            "    da+CONJ\n",
            "  güzel:\n",
            "    güzel+ADJ\n",
            "    güzel+ADV\n",
            "    güzel+NOUN\n",
            "\n",
            "'gel buraya!':\n",
            "  gel:\n",
            "    gel+VERB+IMP+2SG\n",
            "  buraya!:\n",
            "    bura+NOUN+DAT+PUNCT.exclamation\n",
            "\n",
            "'oraya git':\n",
            "  oraya:\n",
            "    ora+NOUN+DAT\n",
            "  git:\n",
            "    git+VERB+IMP+2SG\n",
            "\n",
            "'yukarı çık':\n",
            "  yukarı:\n",
            "    yukarı+ADJ\n",
            "    yukarı+ADV\n",
            "    yukarı+NOUN\n",
            "  çık:\n",
            "    çık+VERB+IMP+2SG\n",
            "\n",
            "'ben yemeğe gidiyorum gelecek misin?':\n",
            "  ben:\n",
            "    ben+NOUN\n",
            "    ben+PRON\n",
            "    ben+PRON\n",
            "  yemeğe:\n",
            "    yemek+NOUN+DAT\n",
            "  gidiyorum:\n",
            "    git+VERB+PRES.CONT+1SG\n",
            "  gelecek:\n",
            "    gel+VERB+FUT+3SG\n",
            "    gel+VERB+FUT+3SG\n",
            "    gelecek+ADJ\n",
            "    ... and 3 more\n",
            "  misin?:\n",
            "    mi+QUES+2SG+PUNCT.question\n",
            "\n",
            "'kitabı aldım':\n",
            "  kitabı:\n",
            "    kitap+NOUN+ACC\n",
            "  aldım:\n",
            "    al+VERB+PAST+1SG\n",
            "\n",
            "'ağaca çıktı':\n",
            "  ağaca:\n",
            "    ağa+ADJ+EQU\n",
            "    ağa+NOUN+EQU\n",
            "    ağaç+ADJ+DAT\n",
            "    ... and 1 more\n",
            "  çıktı:\n",
            "    çık+VERB+PAST+3SG\n",
            "    çık+VERB+PAST+3SG\n",
            "    çıktı+NOUN\n",
            "\n",
            "============================================================\n",
            "✅ TURKISH MORPHOLOGICAL ANALYZER - COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Lexical Categories:\n",
            "  ✓ Ad (Noun), Sıfat (Adjective), Zamir (Pronoun)\n",
            "  ✓ Fiil (Verb) with all moods\n",
            "  ✓ Zarf (Adverb), Edat (Postposition)\n",
            "  ✓ Ünlem (Interjection), Bağlaç (Conjunction)\n",
            "  ✓ Question Particles\n",
            "\n",
            "Verb Moods (Bildirme + Dilek Kipleri):\n",
            "  ✓ Present Continuous, Future, Aorist, Past, Inferential\n",
            "  ✓ Optative (İstek), Conditional (Şart), Necessitative (Gereklilik)\n",
            "  ✓ Imperative (Emir)\n",
            "\n",
            "Features:\n",
            "  ✓ Derivational suffixes (-lık, -lik, etc.)\n",
            "  ✓ Voice (passive, reflexive, reciprocal, causative)\n",
            "  ✓ Ability (-ebil/-abil)\n",
            "  ✓ Negation (-ma/-me)\n",
            "  ✓ Punctuation handling\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "import pynini\n",
        "import json\n",
        "\n",
        "# ===== LOAD LEXICON FROM JSON =====\n",
        "def load_lexicon(json_file='turkish_lexicon.json'):\n",
        "    \"\"\"Load Turkish lexicon from JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: {json_file} not found. Using default minimal lexicon.\")\n",
        "        return {\n",
        "            \"nouns\": [\"ev\", \"kitap\", \"masa\"],\n",
        "            \"verbs\": [\"gel\", \"git\", \"oku\"],\n",
        "            \"adjectives\": [\"güzel\", \"iyi\"],\n",
        "            \"pronouns\": [\"ben\", \"sen\", \"o\"],\n",
        "            \"adverbs\": [\"çok\", \"az\"],\n",
        "            \"conjunctions\": [\"ve\", \"da\", \"de\"],\n",
        "            \"postpositions\": [\"gibi\", \"için\"],\n",
        "            \"proper_nouns\": []\n",
        "        }\n",
        "\n",
        "# Load lexicon\n",
        "lexicon = load_lexicon()\n",
        "\n",
        "# ===== HELPER FUNCTIONS =====\n",
        "def extract_verb_root(verb_infinitive):\n",
        "    \"\"\"Extract verb root from infinitive form (remove -mak/-mek).\"\"\"\n",
        "    if verb_infinitive.endswith('mak'):\n",
        "        return verb_infinitive[:-3]\n",
        "    elif verb_infinitive.endswith('mek'):\n",
        "        return verb_infinitive[:-3]\n",
        "    else:\n",
        "        # If it doesn't end with -mak/-mek, return as is (might be already a root)\n",
        "        return verb_infinitive\n",
        "\n",
        "def create_alternating_roots(words, tag):\n",
        "    \"\"\"\n",
        "    Create FST roots with consonant softening (ünsüz yumuşaması).\n",
        "    p→b, ç→c, t→d, k→g/ğ when followed by vowel-initial suffix.\n",
        "    \"\"\"\n",
        "    roots = []\n",
        "\n",
        "    for word in words:\n",
        "        # Original form (before consonant-initial suffixes)\n",
        "        roots.append(pynini.cross(word, f\"{word}+{tag}\"))\n",
        "\n",
        "        # Check if word ends with p, ç, t, k (sert ünsüz)\n",
        "        if len(word) > 1 and word[-1] in ['p', 'ç', 't', 'k']:\n",
        "            # Get the stem without final consonant\n",
        "            stem = word[:-1]\n",
        "            final = word[-1]\n",
        "\n",
        "            # Determine softened form (yumuşak ünsüz)\n",
        "            if final == 'p':\n",
        "                softened = stem + 'b'\n",
        "            elif final == 'ç':\n",
        "                softened = stem + 'c'\n",
        "            elif final == 't':\n",
        "                softened = stem + 'd'\n",
        "            elif final == 'k':\n",
        "                # k → ğ after vowels, k → g after consonants\n",
        "                if len(stem) > 0 and stem[-1] in 'aeıioöuü':\n",
        "                    softened = stem + 'ğ'\n",
        "                else:\n",
        "                    softened = stem + 'g'\n",
        "\n",
        "            # Add softened form (before vowel-initial suffixes)\n",
        "            roots.append(pynini.cross(softened, f\"{word}+{tag}\"))\n",
        "\n",
        "    return pynini.union(*roots) if roots else pynini.cross(\"\", \"\")\n",
        "\n",
        "# ===== ROOTS BY LEXICAL CATEGORY =====\n",
        "\n",
        "# Nouns (Ad) - with consonant softening\n",
        "noun_roots = create_alternating_roots(\n",
        "    lexicon.get('nouns', []),\n",
        "    'NOUN'\n",
        ") if lexicon.get('nouns') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Adjectives (Sıfat) - with consonant softening\n",
        "adj_roots = create_alternating_roots(\n",
        "    lexicon.get('adjectives', []),\n",
        "    'ADJ'\n",
        ") if lexicon.get('adjectives') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Verbs (Fiil) - extract roots and apply consonant softening\n",
        "verb_root_list = [extract_verb_root(word) for word in lexicon.get('verbs', [])]\n",
        "verb_roots = create_alternating_roots(\n",
        "    verb_root_list,\n",
        "    'VERB'\n",
        ") if verb_root_list else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Pronouns (Zamir) - usually don't undergo consonant softening, but include for completeness\n",
        "pronoun_roots = pynini.union(*[\n",
        "    pynini.cross(word, f\"{word}+PRON\")\n",
        "    for word in lexicon.get('pronouns', [])\n",
        "]) if lexicon.get('pronouns') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Adverbs (Zarf) - no inflection\n",
        "adverb_roots = pynini.union(*[\n",
        "    pynini.cross(word, f\"{word}+ADV\")\n",
        "    for word in lexicon.get('adverbs', [])\n",
        "]) if lexicon.get('adverbs') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Postpositions (Edat) - no inflection\n",
        "postposition_roots = pynini.union(*[\n",
        "    pynini.cross(word, f\"{word}+POSTP\")\n",
        "    for word in lexicon.get('postpositions', [])\n",
        "]) if lexicon.get('postpositions') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Interjections (Ünlem) - no inflection\n",
        "interjection_roots = pynini.union(*[\n",
        "    pynini.cross(word, f\"{word}+INTERJ\")\n",
        "    for word in lexicon.get('interjections', [])\n",
        "]) if lexicon.get('interjections') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Conjunctions (Bağlaç) - no inflection\n",
        "conjunction_roots = pynini.union(*[\n",
        "    pynini.cross(word, f\"{word}+CONJ\")\n",
        "    for word in lexicon.get('conjunctions', [])\n",
        "]) if lexicon.get('conjunctions') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Proper Nouns (Özel İsimler) - with consonant softening\n",
        "proper_noun_roots = create_alternating_roots(\n",
        "    lexicon.get('proper_nouns', []),\n",
        "    'PROPN'\n",
        ") if lexicon.get('proper_nouns') else pynini.cross(\"\", \"\")\n",
        "\n",
        "# Question Particles\n",
        "question_particles = pynini.union(\n",
        "    pynini.cross(\"mi\", \"mi+QUES\"),\n",
        "    pynini.cross(\"mı\", \"mı+QUES\"),\n",
        "    pynini.cross(\"mu\", \"mu+QUES\"),\n",
        "    pynini.cross(\"mü\", \"mü+QUES\"),\n",
        "    pynini.cross(\"misin\", \"mi+QUES+2SG\"),\n",
        "    pynini.cross(\"mısın\", \"mı+QUES+2SG\"),\n",
        "    pynini.cross(\"musun\", \"mu+QUES+2SG\"),\n",
        "    pynini.cross(\"müsün\", \"mü+QUES+2SG\"),\n",
        "    pynini.cross(\"miyim\", \"mi+QUES+1SG\"),\n",
        "    pynini.cross(\"mıyım\", \"mı+QUES+1SG\"),\n",
        "    pynini.cross(\"muyum\", \"mu+QUES+1SG\"),\n",
        "    pynini.cross(\"müyüm\", \"mü+QUES+1SG\"),\n",
        "    pynini.cross(\"miyiz\", \"mi+QUES+1PL\"),\n",
        "    pynini.cross(\"mıyız\", \"mı+QUES+1PL\"),\n",
        "    pynini.cross(\"muyuz\", \"mu+QUES+1PL\"),\n",
        "    pynini.cross(\"müyüz\", \"mü+QUES+1PL\"),\n",
        "    pynini.cross(\"misiniz\", \"mi+QUES+2PL\"),\n",
        "    pynini.cross(\"mısınız\", \"mı+QUES+2PL\"),\n",
        "    pynini.cross(\"musunuz\", \"mu+QUES+2PL\"),\n",
        "    pynini.cross(\"müsünüz\", \"mü+QUES+2PL\")\n",
        ")\n",
        "\n",
        "# ===== DERIVATIONAL SUFFIXES =====\n",
        "derivational = pynini.union(\n",
        "    pynini.cross(\"lık\", \"+DER.lık\"), pynini.cross(\"lik\", \"+DER.lik\"),\n",
        "    pynini.cross(\"luk\", \"+DER.luk\"), pynini.cross(\"lük\", \"+DER.lük\"),\n",
        "    pynini.cross(\"cı\", \"+DER.cı\"), pynini.cross(\"ci\", \"+DER.ci\"),\n",
        "    pynini.cross(\"cu\", \"+DER.cu\"), pynini.cross(\"cü\", \"+DER.cü\"),\n",
        "    pynini.cross(\"çı\", \"+DER.çı\"), pynini.cross(\"çi\", \"+DER.çi\"),\n",
        "    pynini.cross(\"çu\", \"+DER.çu\"), pynini.cross(\"çü\", \"+DER.çü\"),\n",
        "    pynini.cross(\"sız\", \"+DER.sız\"), pynini.cross(\"siz\", \"+DER.siz\"),\n",
        "    pynini.cross(\"suz\", \"+DER.suz\"), pynini.cross(\"süz\", \"+DER.süz\"),\n",
        "    pynini.cross(\"lı\", \"+DER.lı\"), pynini.cross(\"li\", \"+DER.li\"),\n",
        "    pynini.cross(\"lu\", \"+DER.lu\"), pynini.cross(\"lü\", \"+DER.lü\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "# ===== NOUN/ADJECTIVE MORPHOLOGY =====\n",
        "# Include proper nouns that can take case markers\n",
        "nominal_roots = pynini.union(noun_roots, adj_roots, pronoun_roots, proper_noun_roots)\n",
        "nominal_derived = nominal_roots + derivational\n",
        "\n",
        "plural = pynini.union(\n",
        "    pynini.cross(\"lar\", \"+PL\"),\n",
        "    pynini.cross(\"ler\", \"+PL\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "nominal_pl = nominal_derived + plural\n",
        "\n",
        "possessive = pynini.union(\n",
        "    pynini.cross(\"imiz\", \"+POSS.1PL\"), pynini.cross(\"ımız\", \"+POSS.1PL\"),\n",
        "    pynini.cross(\"umuz\", \"+POSS.1PL\"), pynini.cross(\"ümüz\", \"+POSS.1PL\"),\n",
        "    pynini.cross(\"iniz\", \"+POSS.2PL\"), pynini.cross(\"ınız\", \"+POSS.2PL\"),\n",
        "    pynini.cross(\"unuz\", \"+POSS.2PL\"), pynini.cross(\"ünüz\", \"+POSS.2PL\"),\n",
        "    pynini.cross(\"leri\", \"+POSS.3PL\"), pynini.cross(\"ları\", \"+POSS.3PL\"),\n",
        "    pynini.cross(\"im\", \"+POSS.1SG\"), pynini.cross(\"ım\", \"+POSS.1SG\"),\n",
        "    pynini.cross(\"um\", \"+POSS.1SG\"), pynini.cross(\"üm\", \"+POSS.1SG\"),\n",
        "    pynini.cross(\"in\", \"+POSS.2SG\"), pynini.cross(\"ın\", \"+POSS.2SG\"),\n",
        "    pynini.cross(\"un\", \"+POSS.2SG\"), pynini.cross(\"ün\", \"+POSS.2SG\"),\n",
        "    pynini.cross(\"si\", \"+POSS.3SG\"), pynini.cross(\"sı\", \"+POSS.3SG\"),\n",
        "    pynini.cross(\"su\", \"+POSS.3SG\"), pynini.cross(\"sü\", \"+POSS.3SG\")\n",
        ")\n",
        "\n",
        "case_after_poss = pynini.union(\n",
        "    pynini.cross(\"dan\", \"+ABL\"), pynini.cross(\"den\", \"+ABL\"),\n",
        "    pynini.cross(\"tan\", \"+ABL\"), pynini.cross(\"ten\", \"+ABL\"),\n",
        "    pynini.cross(\"ndan\", \"+ABL\"), pynini.cross(\"nden\", \"+ABL\"),\n",
        "    pynini.cross(\"ntan\", \"+ABL\"), pynini.cross(\"nten\", \"+ABL\"),\n",
        "    pynini.cross(\"nın\", \"+GEN\"), pynini.cross(\"nin\", \"+GEN\"),\n",
        "    pynini.cross(\"nun\", \"+GEN\"), pynini.cross(\"nün\", \"+GEN\"),\n",
        "    pynini.cross(\"da\", \"+LOC\"), pynini.cross(\"de\", \"+LOC\"),\n",
        "    pynini.cross(\"ta\", \"+LOC\"), pynini.cross(\"te\", \"+LOC\"),\n",
        "    pynini.cross(\"nda\", \"+LOC\"), pynini.cross(\"nde\", \"+LOC\"),\n",
        "    pynini.cross(\"nta\", \"+LOC\"), pynini.cross(\"nte\", \"+LOC\"),\n",
        "    pynini.cross(\"ya\", \"+DAT\"), pynini.cross(\"ye\", \"+DAT\"),\n",
        "    pynini.cross(\"na\", \"+DAT\"), pynini.cross(\"ne\", \"+DAT\"),\n",
        "    pynini.cross(\"yı\", \"+ACC\"), pynini.cross(\"yi\", \"+ACC\"),\n",
        "    pynini.cross(\"yu\", \"+ACC\"), pynini.cross(\"yü\", \"+ACC\"),\n",
        "    pynini.cross(\"nı\", \"+ACC\"), pynini.cross(\"ni\", \"+ACC\"),\n",
        "    pynini.cross(\"nu\", \"+ACC\"), pynini.cross(\"nü\", \"+ACC\"),\n",
        "    pynini.cross(\"yla\", \"+INS\"), pynini.cross(\"yle\", \"+INS\"),\n",
        "    pynini.cross(\"ca\", \"+EQU\"), pynini.cross(\"ce\", \"+EQU\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "ki_suffix = pynini.union(\n",
        "    pynini.cross(\"ki\", \"+KI\"),\n",
        "    pynini.cross(\"kü\", \"+KI\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "plural_after_ki = pynini.union(\n",
        "    pynini.cross(\"ler\", \"+PL\"),\n",
        "    pynini.cross(\"lar\", \"+PL\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "possessive_path = nominal_pl + possessive + case_after_poss + ki_suffix + plural_after_ki\n",
        "\n",
        "case_no_poss = pynini.union(\n",
        "    pynini.cross(\"ların\", \"+GEN\"), pynini.cross(\"lerin\", \"+GEN\"),\n",
        "    pynini.cross(\"dan\", \"+ABL\"), pynini.cross(\"den\", \"+ABL\"),\n",
        "    pynini.cross(\"tan\", \"+ABL\"), pynini.cross(\"ten\", \"+ABL\"),\n",
        "    pynini.cross(\"nın\", \"+GEN\"), pynini.cross(\"nin\", \"+GEN\"),\n",
        "    pynini.cross(\"nun\", \"+GEN\"), pynini.cross(\"nün\", \"+GEN\"),\n",
        "    pynini.cross(\"da\", \"+LOC\"), pynini.cross(\"de\", \"+LOC\"),\n",
        "    pynini.cross(\"ta\", \"+LOC\"), pynini.cross(\"te\", \"+LOC\"),\n",
        "    pynini.cross(\"ya\", \"+DAT\"), pynini.cross(\"ye\", \"+DAT\"),\n",
        "    pynini.cross(\"a\", \"+DAT\"), pynini.cross(\"e\", \"+DAT\"),\n",
        "    pynini.cross(\"yı\", \"+ACC\"), pynini.cross(\"yi\", \"+ACC\"),\n",
        "    pynini.cross(\"yu\", \"+ACC\"), pynini.cross(\"yü\", \"+ACC\"),\n",
        "    pynini.cross(\"ı\", \"+ACC\"), pynini.cross(\"i\", \"+ACC\"),\n",
        "    pynini.cross(\"u\", \"+ACC\"), pynini.cross(\"ü\", \"+ACC\"),\n",
        "    pynini.cross(\"la\", \"+INS\"), pynini.cross(\"le\", \"+INS\"),\n",
        "    pynini.cross(\"yla\", \"+INS\"), pynini.cross(\"yle\", \"+INS\"),\n",
        "    pynini.cross(\"ca\", \"+EQU\"), pynini.cross(\"ce\", \"+EQU\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "ki_suffix_case = pynini.union(\n",
        "    pynini.cross(\"ki\", \"+KI\"),\n",
        "    pynini.cross(\"kü\", \"+KI\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "plural_after_ki_case = pynini.union(\n",
        "    pynini.cross(\"ler\", \"+PL\"),\n",
        "    pynini.cross(\"lar\", \"+PL\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "case_only_path = nominal_pl + case_no_poss + ki_suffix_case + plural_after_ki_case\n",
        "\n",
        "nominal_base = pynini.union(possessive_path, case_only_path).optimize()\n",
        "\n",
        "copula = pynini.union(\n",
        "    pynini.cross(\"ydi\", \"+COP.PAST\"), pynini.cross(\"ydı\", \"+COP.PAST\"),\n",
        "    pynini.cross(\"ydu\", \"+COP.PAST\"), pynini.cross(\"ydü\", \"+COP.PAST\"),\n",
        "    pynini.cross(\"ymış\", \"+COP.EVID\"), pynini.cross(\"ymiş\", \"+COP.EVID\"),\n",
        "    pynini.cross(\"ymuş\", \"+COP.EVID\"), pynini.cross(\"ymüş\", \"+COP.EVID\"),\n",
        "    pynini.cross(\"yse\", \"+COP.COND\"), pynini.cross(\"ysa\", \"+COP.COND\"),\n",
        "    pynini.cross(\"di\", \"+COP.PAST\"), pynini.cross(\"dı\", \"+COP.PAST\"),\n",
        "    pynini.cross(\"du\", \"+COP.PAST\"), pynini.cross(\"dü\", \"+COP.PAST\"),\n",
        "    pynini.cross(\"ti\", \"+COP.PAST\"), pynini.cross(\"tı\", \"+COP.PAST\"),\n",
        "    pynini.cross(\"tu\", \"+COP.PAST\"), pynini.cross(\"tü\", \"+COP.PAST\"),\n",
        "    pynini.cross(\"miş\", \"+COP.EVID\"), pynini.cross(\"mış\", \"+COP.EVID\"),\n",
        "    pynini.cross(\"muş\", \"+COP.EVID\"), pynini.cross(\"müş\", \"+COP.EVID\"),\n",
        "    pynini.cross(\"se\", \"+COP.COND\"), pynini.cross(\"sa\", \"+COP.COND\"),\n",
        "    pynini.cross(\"dir\", \"+COP.PRES\"), pynini.cross(\"dır\", \"+COP.PRES\"),\n",
        "    pynini.cross(\"dur\", \"+COP.PRES\"), pynini.cross(\"dür\", \"+COP.PRES\"),\n",
        "    pynini.cross(\"tir\", \"+COP.PRES\"), pynini.cross(\"tır\", \"+COP.PRES\"),\n",
        "    pynini.cross(\"tur\", \"+COP.PRES\"), pynini.cross(\"tür\", \"+COP.PRES\")\n",
        ")\n",
        "\n",
        "person = pynini.union(\n",
        "    pynini.cross(\"im\", \"+1SG\"), pynini.cross(\"ım\", \"+1SG\"),\n",
        "    pynini.cross(\"um\", \"+1SG\"), pynini.cross(\"üm\", \"+1SG\"),\n",
        "    pynini.cross(\"in\", \"+2SG\"), pynini.cross(\"ın\", \"+2SG\"),\n",
        "    pynini.cross(\"un\", \"+2SG\"), pynini.cross(\"ün\", \"+2SG\"),\n",
        "    pynini.cross(\"ız\", \"+1PL\"), pynini.cross(\"iz\", \"+1PL\"),\n",
        "    pynini.cross(\"uz\", \"+1PL\"), pynini.cross(\"üz\", \"+1PL\"),\n",
        "    pynini.cross(\"nız\", \"+2PL\"), pynini.cross(\"niz\", \"+2PL\"),\n",
        "    pynini.cross(\"nuz\", \"+2PL\"), pynini.cross(\"nüz\", \"+2PL\"),\n",
        "    pynini.cross(\"lar\", \"+3PL\"), pynini.cross(\"ler\", \"+3PL\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "nominal_with_cop = copula + person\n",
        "nominal_without_cop = pynini.cross(\"\", \"\")\n",
        "nominal_complete = nominal_base + pynini.union(nominal_with_cop, nominal_without_cop).optimize()\n",
        "\n",
        "# ===== VERB MORPHOLOGY =====\n",
        "\n",
        "# Voice, Ability, Negation (all optional)\n",
        "voice = pynini.union(\n",
        "    pynini.cross(\"ıl\", \"+PASS\"), pynini.cross(\"il\", \"+PASS\"),\n",
        "    pynini.cross(\"ul\", \"+PASS\"), pynini.cross(\"ül\", \"+PASS\"),\n",
        "    pynini.cross(\"ın\", \"+REFL\"), pynini.cross(\"in\", \"+REFL\"),\n",
        "    pynini.cross(\"un\", \"+REFL\"), pynini.cross(\"ün\", \"+REFL\"),\n",
        "    pynini.cross(\"lan\", \"+REFL\"), pynini.cross(\"len\", \"+REFL\"),\n",
        "    pynini.cross(\"ış\", \"+RECIP\"), pynini.cross(\"iş\", \"+RECIP\"),\n",
        "    pynini.cross(\"uş\", \"+RECIP\"), pynini.cross(\"üş\", \"+RECIP\"),\n",
        "    pynini.cross(\"t\", \"+CAUS\"), pynini.cross(\"d\", \"+CAUS\"),\n",
        "    pynini.cross(\"dır\", \"+CAUS\"), pynini.cross(\"dir\", \"+CAUS\"),\n",
        "    pynini.cross(\"dur\", \"+CAUS\"), pynini.cross(\"dür\", \"+CAUS\"),\n",
        "    pynini.cross(\"tır\", \"+CAUS\"), pynini.cross(\"tir\", \"+CAUS\"),\n",
        "    pynini.cross(\"tur\", \"+CAUS\"), pynini.cross(\"tür\", \"+CAUS\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "ability = pynini.union(\n",
        "    pynini.cross(\"ebil\", \"+ABIL\"),\n",
        "    pynini.cross(\"abil\", \"+ABIL\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "negation = pynini.union(\n",
        "    pynini.cross(\"ma\", \"+NEG\"),\n",
        "    pynini.cross(\"me\", \"+NEG\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "# Bildirme Kipleri (Indicative)\n",
        "indicative_tense = pynini.union(\n",
        "    pynini.cross(\"iyor\", \"+PRES.CONT\"), pynini.cross(\"ıyor\", \"+PRES.CONT\"),\n",
        "    pynini.cross(\"uyor\", \"+PRES.CONT\"), pynini.cross(\"üyor\", \"+PRES.CONT\"),\n",
        "    pynini.cross(\"ecek\", \"+FUT\"), pynini.cross(\"acak\", \"+FUT\"),\n",
        "    pynini.cross(\"ır\", \"+AOR\"), pynini.cross(\"ir\", \"+AOR\"),\n",
        "    pynini.cross(\"ur\", \"+AOR\"), pynini.cross(\"ür\", \"+AOR\"),\n",
        "    pynini.cross(\"ar\", \"+AOR\"), pynini.cross(\"er\", \"+AOR\"),\n",
        "    pynini.cross(\"r\", \"+AOR\"),\n",
        "    pynini.cross(\"dı\", \"+PAST\"), pynini.cross(\"di\", \"+PAST\"),\n",
        "    pynini.cross(\"du\", \"+PAST\"), pynini.cross(\"dü\", \"+PAST\"),\n",
        "    pynini.cross(\"tı\", \"+PAST\"), pynini.cross(\"ti\", \"+PAST\"),\n",
        "    pynini.cross(\"tu\", \"+PAST\"), pynini.cross(\"tü\", \"+PAST\"),\n",
        "    pynini.cross(\"mış\", \"+INFER\"), pynini.cross(\"miş\", \"+INFER\"),\n",
        "    pynini.cross(\"muş\", \"+INFER\"), pynini.cross(\"müş\", \"+INFER\")\n",
        ")\n",
        "\n",
        "indicative_person = pynini.union(\n",
        "    pynini.cross(\"um\", \"+1SG\"), pynini.cross(\"üm\", \"+1SG\"),\n",
        "    pynini.cross(\"ım\", \"+1SG\"), pynini.cross(\"im\", \"+1SG\"),\n",
        "    pynini.cross(\"m\", \"+1SG\"),\n",
        "    pynini.cross(\"sun\", \"+2SG\"), pynini.cross(\"sün\", \"+2SG\"),\n",
        "    pynini.cross(\"sın\", \"+2SG\"), pynini.cross(\"sin\", \"+2SG\"),\n",
        "    pynini.cross(\"n\", \"+2SG\"),\n",
        "    pynini.cross(\"uz\", \"+1PL\"), pynini.cross(\"üz\", \"+1PL\"),\n",
        "    pynini.cross(\"ız\", \"+1PL\"), pynini.cross(\"iz\", \"+1PL\"),\n",
        "    pynini.cross(\"k\", \"+1PL\"),\n",
        "    pynini.cross(\"sunuz\", \"+2PL\"), pynini.cross(\"sünüz\", \"+2PL\"),\n",
        "    pynini.cross(\"sınız\", \"+2PL\"), pynini.cross(\"siniz\", \"+2PL\"),\n",
        "    pynini.cross(\"nız\", \"+2PL\"), pynini.cross(\"niz\", \"+2PL\"),\n",
        "    pynini.cross(\"nuz\", \"+2PL\"), pynini.cross(\"nüz\", \"+2PL\"),\n",
        "    pynini.cross(\"lar\", \"+3PL\"), pynini.cross(\"ler\", \"+3PL\"),\n",
        "    pynini.cross(\"\", \"+3SG\")\n",
        ")\n",
        "\n",
        "# Dilek/Tasarlama Kipleri (Subjunctive/Optative)\n",
        "\n",
        "# İstek Kipi (Optative)\n",
        "optative_mood_person = pynini.union(\n",
        "    pynini.cross(\"ayım\", \"+OPT+1SG\"), pynini.cross(\"eyim\", \"+OPT+1SG\"),\n",
        "    pynini.cross(\"ayum\", \"+OPT+1SG\"), pynini.cross(\"eyüm\", \"+OPT+1SG\"),\n",
        "    pynini.cross(\"asın\", \"+OPT+2SG\"), pynini.cross(\"esin\", \"+OPT+2SG\"),\n",
        "    pynini.cross(\"asun\", \"+OPT+2SG\"), pynini.cross(\"esün\", \"+OPT+2SG\"),\n",
        "    pynini.cross(\"asana\", \"+OPT+2SG+EMPH\"), pynini.cross(\"esene\", \"+OPT+2SG+EMPH\"),\n",
        "    pynini.cross(\"sana\", \"+OPT+2SG+EMPH\"), pynini.cross(\"sene\", \"+OPT+2SG+EMPH\"),\n",
        "    pynini.cross(\"asan\", \"+OPT+2SG\"), pynini.cross(\"esen\", \"+OPT+2SG\"),\n",
        "    pynini.cross(\"a\", \"+OPT+3SG\"), pynini.cross(\"e\", \"+OPT+3SG\"),\n",
        "    pynini.cross(\"alım\", \"+OPT+1PL\"), pynini.cross(\"elim\", \"+OPT+1PL\"),\n",
        "    pynini.cross(\"alum\", \"+OPT+1PL\"), pynini.cross(\"elüm\", \"+OPT+1PL\"),\n",
        "    pynini.cross(\"asınız\", \"+OPT+2PL\"), pynini.cross(\"esiniz\", \"+OPT+2PL\"),\n",
        "    pynini.cross(\"asunuz\", \"+OPT+2PL\"), pynini.cross(\"esünüz\", \"+OPT+2PL\"),\n",
        "    pynini.cross(\"alar\", \"+OPT+3PL\"), pynini.cross(\"eler\", \"+OPT+3PL\")\n",
        ")\n",
        "\n",
        "# Dilek-Koşul Kipi (Conditional)\n",
        "conditional_mood_person = pynini.union(\n",
        "    pynini.cross(\"sam\", \"+COND+1SG\"), pynini.cross(\"sem\", \"+COND+1SG\"),\n",
        "    pynini.cross(\"san\", \"+COND+2SG\"), pynini.cross(\"sen\", \"+COND+2SG\"),\n",
        "    pynini.cross(\"sa\", \"+COND+3SG\"), pynini.cross(\"se\", \"+COND+3SG\"),\n",
        "    pynini.cross(\"sak\", \"+COND+1PL\"), pynini.cross(\"sek\", \"+COND+1PL\"),\n",
        "    pynini.cross(\"sanız\", \"+COND+2PL\"), pynini.cross(\"seniz\", \"+COND+2PL\"),\n",
        "    pynini.cross(\"sanuz\", \"+COND+2PL\"), pynini.cross(\"senüz\", \"+COND+2PL\"),\n",
        "    pynini.cross(\"salar\", \"+COND+3PL\"), pynini.cross(\"seler\", \"+COND+3PL\")\n",
        ")\n",
        "\n",
        "# ...\n",
        "\n",
        "\n",
        "# Gereklilik Kipi (Necessitative)\n",
        "necessitative_mood_person = pynini.union(\n",
        "    pynini.cross(\"malıyım\", \"+NEC+1SG\"), pynini.cross(\"meliyim\", \"+NEC+1SG\"),\n",
        "    pynini.cross(\"malıyum\", \"+NEC+1SG\"), pynini.cross(\"meliyüm\", \"+NEC+1SG\"),\n",
        "    pynini.cross(\"malısın\", \"+NEC+2SG\"), pynini.cross(\"melisin\", \"+NEC+2SG\"),\n",
        "    pynini.cross(\"malısun\", \"+NEC+2SG\"), pynini.cross(\"melisün\", \"+NEC+2SG\"),\n",
        "    pynini.cross(\"malı\", \"+NEC+3SG\"), pynini.cross(\"meli\", \"+NEC+3SG\"),\n",
        "    pynini.cross(\"malıyız\", \"+NEC+1PL\"), pynini.cross(\"meliyiz\", \"+NEC+1PL\"),\n",
        "    pynini.cross(\"malıyuz\", \"+NEC+1PL\"), pynini.cross(\"meliyüz\", \"+NEC+1PL\"),\n",
        "    pynini.cross(\"malısınız\", \"+NEC+2PL\"), pynini.cross(\"melisiniz\", \"+NEC+2PL\"),\n",
        "    pynini.cross(\"malısunuz\", \"+NEC+2PL\"), pynini.cross(\"melisünüz\", \"+NEC+2PL\"),\n",
        "    pynini.cross(\"malılar\", \"+NEC+3PL\"), pynini.cross(\"meliler\", \"+NEC+3PL\")\n",
        ")\n",
        "\n",
        "# Emir Kipi (Imperative)\n",
        "imperative_mood_person = pynini.union(\n",
        "    pynini.cross(\"sin\", \"+IMP+3SG\"), pynini.cross(\"sın\", \"+IMP+3SG\"),\n",
        "    pynini.cross(\"sun\", \"+IMP+3SG\"), pynini.cross(\"sün\", \"+IMP+3SG\"),\n",
        "    pynini.cross(\"in\", \"+IMP+2PL\"), pynini.cross(\"ın\", \"+IMP+2PL\"),\n",
        "    pynini.cross(\"un\", \"+IMP+2PL\"), pynini.cross(\"ün\", \"+IMP+2PL\"),\n",
        "    pynini.cross(\"iniz\", \"+IMP+2PL\"), pynini.cross(\"ınız\", \"+IMP+2PL\"),\n",
        "    pynini.cross(\"unuz\", \"+IMP+2PL\"), pynini.cross(\"ünüz\", \"+IMP+2PL\"),\n",
        "    pynini.cross(\"sinler\", \"+IMP+3PL\"), pynini.cross(\"sınlar\", \"+IMP+3PL\"),\n",
        "    pynini.cross(\"sunlar\", \"+IMP+3PL\"), pynini.cross(\"sünler\", \"+IMP+3PL\")\n",
        ")\n",
        "\n",
        "imperative_2sg_bare = pynini.cross(\"\", \"+IMP+2SG\")\n",
        "\n",
        "# Build verb structure\n",
        "verb_base = verb_roots + voice + ability + negation\n",
        "\n",
        "# Verb paths\n",
        "verb_indicative = verb_base + indicative_tense + indicative_person\n",
        "verb_optative = verb_base + optative_mood_person\n",
        "verb_conditional = verb_base + conditional_mood_person\n",
        "verb_necessitative = verb_base + necessitative_mood_person\n",
        "verb_imperative = verb_base + pynini.union(imperative_mood_person, imperative_2sg_bare)\n",
        "\n",
        "# Combine all verb paths\n",
        "verb_complete = pynini.union(\n",
        "    verb_indicative,\n",
        "    verb_optative,\n",
        "    verb_conditional,\n",
        "    verb_necessitative,\n",
        "    verb_imperative\n",
        ").optimize()\n",
        "\n",
        "# ===== PUNCTUATION =====\n",
        "punctuation = pynini.union(\n",
        "    pynini.cross(\".\", \"+PUNCT.period\"),\n",
        "    pynini.cross(\",\", \"+PUNCT.comma\"),\n",
        "    pynini.cross(\"?\", \"+PUNCT.question\"),\n",
        "    pynini.cross(\"!\", \"+PUNCT.exclamation\"),\n",
        "    pynini.cross(\":\", \"+PUNCT.colon\"),\n",
        "    pynini.cross(\";\", \"+PUNCT.semicolon\"),\n",
        "    pynini.cross(\"\", \"\")\n",
        ")\n",
        "\n",
        "# ===== COMPLETE ANALYZER =====\n",
        "simple_categories = pynini.union(\n",
        "    adverb_roots,\n",
        "    postposition_roots,\n",
        "    interjection_roots,\n",
        "    conjunction_roots,\n",
        "    question_particles\n",
        ")\n",
        "\n",
        "nominal_fst = (nominal_complete + punctuation).optimize()\n",
        "verb_fst = (verb_complete + punctuation).optimize()\n",
        "simple_fst = (simple_categories + punctuation).optimize()\n",
        "\n",
        "turkish_analyzer = pynini.union(nominal_fst, verb_fst, simple_fst).optimize()\n",
        "\n",
        "def analyze(word):\n",
        "    \"\"\"Analyze a Turkish word and return all possible analyses.\"\"\"\n",
        "    try:\n",
        "        lattice = pynini.compose(word, turkish_analyzer)\n",
        "        analyses = []\n",
        "        seen = set()\n",
        "        try:\n",
        "            for path in lattice.paths().ostrings():\n",
        "                if path not in seen:\n",
        "                    analyses.append(path)\n",
        "                    seen.add(path)\n",
        "        except:\n",
        "            pass\n",
        "        return sorted(analyses) if analyses else [f\"No analysis found for: {word}\"]\n",
        "    except Exception as e:\n",
        "        return [f\"Error: {str(e)}\"]\n",
        "\n",
        "def disambiguate_analyses(word, analyses, prefer_verb=False):\n",
        "    \"\"\"\n",
        "    Apply simple heuristics to reduce ambiguity.\n",
        "    This is a basic rule-based approach. For production use,\n",
        "    statistical/neural methods are recommended.\n",
        "    \"\"\"\n",
        "    if not analyses or analyses[0].startswith(\"No analysis\"):\n",
        "        return analyses\n",
        "\n",
        "    filtered = []\n",
        "\n",
        "    for analysis in analyses:\n",
        "        skip = False\n",
        "\n",
        "        # Rule 1: \"misin\", \"misin?\", etc. are question particles, not \"mis+POSS\"\n",
        "        if any(q in word.lower() for q in ['misin', 'mısın', 'musun', 'müsün', 'miyim', 'mıyım']):\n",
        "            if \"+QUES+\" in analysis:\n",
        "                filtered.append(analysis)\n",
        "                skip = True\n",
        "            elif \"+NOUN+POSS\" in analysis:\n",
        "                skip = True  # Skip mis+NOUN+POSS\n",
        "\n",
        "        # Rule 2: Words ending with -dım/-dim/-dum/-düm are likely VERB+PAST+1SG\n",
        "        if not skip and word.endswith(('dım', 'dim', 'dum', 'düm')):\n",
        "            if \"+VERB+PAST+1SG\" in analysis:\n",
        "                filtered.append(analysis)\n",
        "                skip = True\n",
        "            else:\n",
        "                skip = True  # Skip other analyses\n",
        "\n",
        "        # Rule 3: Words ending with -dı/-di/-du/-dü/-tı/-ti/-tu/-tü are likely VERB+PAST\n",
        "        if not skip and word.endswith(('dı', 'di', 'du', 'dü', 'tı', 'ti', 'tu', 'tü')):\n",
        "            if \"+VERB+PAST\" in analysis:\n",
        "                filtered.append(analysis)\n",
        "            # Don't skip others completely, but prefer verb\n",
        "\n",
        "        # Rule 4: Words ending with -yor/-yorum/-yorsun are definitely VERB+PRES.CONT\n",
        "        elif not skip and any(word.endswith(x) for x in ['yor', 'yorum', 'yorsun', 'iyorum', 'ıyorum', 'uyorum', 'üyorum']):\n",
        "            if \"+VERB+PRES.CONT\" in analysis:\n",
        "                filtered.append(analysis)\n",
        "                skip = True\n",
        "            else:\n",
        "                skip = True\n",
        "\n",
        "        # Rule 5: Words ending with -ecek/-acak could be verb or noun, prefer verb in context\n",
        "        elif not skip and word.endswith(('ecek', 'acak', 'eceğim', 'acağım')):\n",
        "            if prefer_verb and \"+VERB+\" in analysis:\n",
        "                filtered.append(analysis)\n",
        "            elif not prefer_verb:\n",
        "                filtered.append(analysis)\n",
        "\n",
        "        # Rule 6: Single syllable pronouns like \"ben\" are likely PRON, not NOUN\n",
        "        elif not skip and word.lower() in ['ben', 'sen', 'biz', 'siz']:\n",
        "            if \"+PRON\" in analysis:\n",
        "                filtered.append(analysis)\n",
        "            # Don't completely skip NOUN, but prefer PRON\n",
        "\n",
        "        # Add anything not caught by rules\n",
        "        if not skip:\n",
        "            filtered.append(analysis)\n",
        "\n",
        "    # If filtering removed everything, return original\n",
        "    return filtered if filtered else analyses\n",
        "\n",
        "def analyze_with_disambiguation(word, prefer_verb=False):\n",
        "    \"\"\"Analyze word and apply basic disambiguation.\"\"\"\n",
        "    raw_analyses = analyze(word)\n",
        "    return disambiguate_analyses(word, raw_analyses, prefer_verb)\n",
        "\n",
        "def analyze_sentence(sentence, use_disambiguation=True):\n",
        "    \"\"\"\n",
        "    Analyze a sentence by tokenizing and analyzing each word.\n",
        "    Optionally applies context-based disambiguation.\n",
        "    \"\"\"\n",
        "    tokens = sentence.split()\n",
        "    results = []\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "        # Simple context: if previous word was a noun, current might be verb\n",
        "        prefer_verb = False\n",
        "        if i > 0 and results:\n",
        "            prev_analyses = results[-1]['analyses']\n",
        "            if any('+NOUN+' in a or '+ADJ+' in a for a in prev_analyses):\n",
        "                prefer_verb = True\n",
        "\n",
        "        if use_disambiguation:\n",
        "            analyses = analyze_with_disambiguation(token, prefer_verb)\n",
        "        else:\n",
        "            analyses = analyze(token)\n",
        "\n",
        "        results.append({\n",
        "            'token': token,\n",
        "            'analyses': analyses\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def save_fst(filename):\n",
        "    \"\"\"Save the compiled FST to a file.\"\"\"\n",
        "    turkish_analyzer.write(filename)\n",
        "    print(f\"FST saved to {filename}\")\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\"LEXICON LOADED\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Nouns: {len(lexicon.get('nouns', []))} words\")\n",
        "    print(f\"Verbs: {len(lexicon.get('verbs', []))} words (infinitives → roots extracted)\")\n",
        "    print(f\"Adjectives: {len(lexicon.get('adjectives', []))} words\")\n",
        "    print(f\"Pronouns: {len(lexicon.get('pronouns', []))} words\")\n",
        "    print(f\"Adverbs: {len(lexicon.get('adverbs', []))} words\")\n",
        "    print(f\"Conjunctions: {len(lexicon.get('conjunctions', []))} words\")\n",
        "    print(f\"Postpositions: {len(lexicon.get('postpositions', []))} words\")\n",
        "    print(f\"Proper Nouns: {len(lexicon.get('proper_nouns', []))} words\")\n",
        "\n",
        "    # Show some verb root examples\n",
        "    if lexicon.get('verbs'):\n",
        "        print(\"\\nVerb root examples:\")\n",
        "        for verb in lexicon.get('verbs', [])[:5]:\n",
        "            root = extract_verb_root(verb)\n",
        "            print(f\"  {verb} → {root}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DEBUG: Testing verb compositions\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test = \"gel\"\n",
        "    try:\n",
        "        lattice = pynini.compose(test, verb_imperative)\n",
        "        print(f\"\\n'{test}' + verb_imperative:\")\n",
        "        for path in lattice.paths().ostrings():\n",
        "            print(f\"  ✓ {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "\n",
        "    test2 = \"gelsin\"\n",
        "    try:\n",
        "        lattice = pynini.compose(test2, verb_imperative)\n",
        "        print(f\"\\n'{test2}' + verb_imperative:\")\n",
        "        for path in lattice.paths().ostrings():\n",
        "            print(f\"  ✓ {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SINGLE WORD ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_words = [\n",
        "        # Dilek Kipleri\n",
        "        \"gel\",            # come! (imperative 2sg)\n",
        "        \"gelin\",          # come! (imperative 2pl)\n",
        "        \"gelsin\",         # let him/her come (imperative 3sg)\n",
        "        \"gelsem\",         # if I come (conditional)\n",
        "        \"geleyim\",        # let me come (optative)\n",
        "        \"gelmeli\",        # must come (necessitative)\n",
        "        \"yazmalıyım\",     # I must write\n",
        "        \"okusana\",        # read then! (optative emphatic)\n",
        "        \"görseler\",       # if they see (conditional)\n",
        "        # Bildirme Kipleri\n",
        "        \"okudum\",         # I read (past)\n",
        "        \"gelebilecek\",    # will be able to come (future)\n",
        "        \"geliyorum\",      # I am coming (present continuous)\n",
        "        # Nouns\n",
        "        \"kitaplardan\",    # from books\n",
        "        \"kalemlik\",       # pencil case\n",
        "        \"evdekiler\",      # those in the house\n",
        "    ]\n",
        "\n",
        "    for word in test_words:\n",
        "        print(f\"\\n{word}:\")\n",
        "        analyses = analyze(word)\n",
        "        for analysis in analyses[:5]:\n",
        "            print(f\"  {analysis}\")\n",
        "        if len(analyses) > 5:\n",
        "            print(f\"  ... and {len(analyses) - 5} more analyses\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MULTI-WORD ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_sentences = [\n",
        "        \"evde misin?\",\n",
        "        \"kitap da güzel\",\n",
        "        \"gel buraya!\",\n",
        "        \"oraya git\",\n",
        "        \"yukarı çık\",\n",
        "        \"ben yemeğe gidiyorum gelecek misin?\",\n",
        "        \"kitabı aldım\",\n",
        "        \"ağaca çıktı\",\n",
        "    ]\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        print(f\"\\n'{sentence}':\")\n",
        "        results = analyze_sentence(sentence)\n",
        "        for result in results:\n",
        "            print(f\"  {result['token']}:\")\n",
        "            for analysis in result['analyses'][:3]:\n",
        "                print(f\"    {analysis}\")\n",
        "            if len(result['analyses']) > 3:\n",
        "                print(f\"    ... and {len(result['analyses']) - 3} more\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in [\"gelecek misin\", \"yapacak mısın\", \"gidiyorum\", \"çıktı\", \"gelecek\", \"ben\"]:\n",
        "    print(f\"\\n{word}:\")\n",
        "    raw = analyze(word)\n",
        "    filtered = analyze_with_disambiguation(word)\n",
        "    print(f\"  RAW ({len(raw)}): {raw}\")\n",
        "    print(f\"  FILTERED ({len(filtered)}): {filtered}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLxaXXEeWzeR",
        "outputId": "dfd23546-cc83-4a63-f15f-403586e13f0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "gelecek misin:\n",
            "  RAW (1): ['No analysis found for: gelecek misin']\n",
            "  FILTERED (1): ['No analysis found for: gelecek misin']\n",
            "\n",
            "yapacak mısın:\n",
            "  RAW (1): ['No analysis found for: yapacak mısın']\n",
            "  FILTERED (1): ['No analysis found for: yapacak mısın']\n",
            "\n",
            "gidiyorum:\n",
            "  RAW (1): ['git+VERB+PRES.CONT+1SG']\n",
            "  FILTERED (1): ['git+VERB+PRES.CONT+1SG']\n",
            "\n",
            "çıktı:\n",
            "  RAW (2): ['çık+VERB+PAST+3SG', 'çıktı+NOUN']\n",
            "  FILTERED (3): ['çık+VERB+PAST+3SG', 'çık+VERB+PAST+3SG', 'çıktı+NOUN']\n",
            "\n",
            "gelecek:\n",
            "  RAW (3): ['gel+VERB+FUT+3SG', 'gelecek+ADJ', 'gelecek+NOUN']\n",
            "  FILTERED (6): ['gel+VERB+FUT+3SG', 'gel+VERB+FUT+3SG', 'gelecek+ADJ', 'gelecek+ADJ', 'gelecek+NOUN', 'gelecek+NOUN']\n",
            "\n",
            "ben:\n",
            "  RAW (2): ['ben+NOUN', 'ben+PRON']\n",
            "  FILTERED (3): ['ben+NOUN', 'ben+PRON', 'ben+PRON']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwNC0Vj63whs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}